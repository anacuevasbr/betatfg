{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Práctica 4</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this exercise is to start using tools for the segmentation of images. In this case we will be segmetating the keys on a calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos librerías necesarias\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I. Histogram and thresholding**\n",
    "\n",
    "Read the image calculador.tif as a gray scale image, display it and answer these questions.\n",
    "\n",
    "    -Are the keys all the same size? Which one is the biggest\n",
    "    -Do all the keys have writng in them? Are they connected?\n",
    "    -Is there writing outside of the keys?\n",
    "    -Which writing is brighter, the one inside or outside the keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the histogram of the image calculadora.tif to identify its different areas (the keys, writing and background). Remember that displaying an image using matplotlib notebook allows you to see the intensity level of a pixel when hovering over it, use this to compare the intensity in the original image and the values on the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram choose a threshold value that will separate the letters on the keys from the other elements. Use this value to get a binary image, save this binary image in the variable I_U, show the result.\n",
    "\n",
    "[answer cell](#thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II. Segmentation and characteritation of regions**\n",
    "\n",
    "A region in image processing is a set of connected pixels that we can label. Segmentation is the process of defining and labeling those regions.\n",
    "Open_CV has a function ([connectedComponentsWithStats](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#ga107a78bf7cd25dec05fb4dfc5c9e765f)) for segmentation, the input has to be a binary image. The other input parameter is the connectivity which defines what <font color=red>is considered a neighbour pixel, if connectivity equals 4 it only counts pixels orthogonally connected, if it equals 8 it also considers diagonally connected pixels</font>.\n",
    "Use the function connectedComponentsWithStats with our image (I_U) and leave the connectivity by default.\n",
    "The function has four outputs:\n",
    "1. retval: number of objects.\n",
    "2. labels: the destination image, name it Seg_I_U.\n",
    "3. Stats: information about the different segments, [here](https://docs.opencv.org/master/d3/dc0/group__imgproc__shape.html#gac7099124c0390051c6970a987e7dc5c5) you can see what parameters it returs, we will be using this later to get the area of the different regions.\n",
    "4. centroids.\n",
    "\n",
    "Display the segmented image using this colormap to help differentiate the regions cmap=plt.cm.get_cmap('nipy_spectral').\n",
    "\n",
    "[answer cell](#segmentedimage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next part of the process we will need the area of the different segments. To access this stat easier create a new array of size (1,Nobjects) where Nobjects is the number of labels, call it V_Area.\n",
    "To access a especific area in the stats matrix use stats(label, CC.STAT_AREA) <font color=green>see example below</font>.\n",
    "\n",
    "Once you have the array V_Area plot it as a bar graph to analyse the results. \n",
    "Keep in mind that the background is considered a region, to better see the areas of the regions of interest we recomend creating a new array without the first label (background) and plotting that.\n",
    "\n",
    "[answer cell](#areasnobg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b95834d2d216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Example of accessing stats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCC_STAT_AREA\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "#Example of accessing stats\n",
    "\n",
    "print(stats[10, cv2.CC_STAT_AREA])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the labelled image (Seg_I_U) you can see that some of the regions don't correspond with letters on the calculator but, most of these regions are small. Analyse the graph with the areas of the regions and decide a threshold value to exclude the regions outside of the keys.\n",
    "Build a new array called V_No_Interest with the numbers of the labels under your decided thersholf (recommended use of the for loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will be filtering the imageto to get rid of the regions outside of the keys.\n",
    "Use Seg_I_U to get the label of each pixel, if their label is in the No interest array that pixel should be 0 in our new filtered image (overwrite I_U for this new image). Plot the new binary image, if you chose the correct threshold in the last segment only the letters of the calculator should have a value of 1, if that's not the case change your threshold and try again.\n",
    "\n",
    "[answer cell](#filtersmallareas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III. Processing to identify the 'Enter' key**\n",
    "\n",
    "Looking at the binary image from the last segment we can see that the letters in the same key are really close toguether, the distance between letters in the same key is always smaller than the distance between letters in other keys. We are going to process the image I_U (from las segment) so all the characters in a region are associated to the same key, this will allow us to identify each key as a different region. Use an spatial filter (with a 5X5 kernel) to filter I_U. Call the resulting image I_U_Fmedia. \n",
    "\n",
    "Keep in mind the data type of the image, if the input of cv2.filter2D() is a binary image the output will also be a binary image.\n",
    "\n",
    "Display the filterd image and its histogram.\n",
    "\n",
    "[answer cell](#filteredimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold the image I_U_Fmedia, choose the threshold value so all the non-zero pixels are inside of the original keys. Display this image (call it I_U_Fmedia_Th). Looking at this image can you count the number of keys accurately? Can you think of a way to get just the 'Enter' key using the commands taught in this exercise?\n",
    "\n",
    "[answer cell](#lastbinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a series of instructions that will result in an image (I_Enter) in gray scale the same size of the original image. This image must have a value of 0 in every pixel except the ones corresponding with the letters spelling 'Enter' in the calculator, this last ones must keep their value from the original image.\n",
    "\n",
    "Hint: it's useful to remember that one of the stats provided by the function cv2.connectedComponentsWithStats() is the area of each of the regions, and that the background is considered as one of the regions.\n",
    "\n",
    "[answer cell](#finalimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cells with the answer images</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Histogram and thresholding\n",
    "\n",
    "<a id='thresholding'></a>\n",
    "\n",
    "![thresholding](answerimages/thresholding.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. Segmentation and characteritation of regions\n",
    "\n",
    "    - Segmented image\n",
    "\n",
    "<a id='segmentedimage1'></a>\n",
    "\n",
    "![segementedimage1](answerimages/segmentedimage1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Areas without background\n",
    "    \n",
    "<a id='areasnobg'></a>\n",
    "\n",
    "![areasnobg](answerimages/areasnobg.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Filtering small areas\n",
    "    \n",
    "<a id='filtersmallareas'></a>\n",
    "\n",
    "![filtersmallareas](answerimages/filtersmallareas.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. Processing to identify the 'Enter' key\n",
    "\n",
    "    - Using a spatial filter\n",
    "\n",
    "<a id='filteredimage'></a>\n",
    "\n",
    "![filteredimage](answerimages/filteredimage.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Thresholding\n",
    "\n",
    "<a id='lastbinary'></a>\n",
    "\n",
    "![lastbinary](answerimages/lastbinary.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Final image\n",
    "\n",
    "<a id='finalimage'></a>\n",
    "\n",
    "![finalimage](answerimages/finalimage.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
