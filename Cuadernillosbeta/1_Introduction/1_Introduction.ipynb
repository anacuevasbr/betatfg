{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Exercise 1</center>\n",
    "** <center>Introduction to digital image processing</center> **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the whole notebook once before starting to solve it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Reading, writing and viewing images\n",
    "\n",
    "In this notebook we are going to be using 3 python lybraries commonly used for image processing:\n",
    "\n",
    "    -OpenCV: Open Source Computer Vision Library\n",
    "    -Numpy: The fundamental package for scientific computing with Python\n",
    "    -Matplotlib: a Python 2D plotting library\n",
    "The first thing we are going to do is import these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to read an image ('lena.jpg') using the function imread from OpenCV. You can find information about it's arguments and output in this [link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html)\n",
    "\n",
    "It's important to make sure that the image we are trying to read is in the correct directory. If the image is not found python won't raise an exception, imread will return a null array.\n",
    "\n",
    "(Try using print to see your matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the image we just read we can use the attributes size, shape, dtype. \n",
    "[More information about numpy types](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the image we have a function in two of the imported libraries: opencv and matplotlib.\n",
    "The opencv option opens the image in a separate window and requires the function waitKey to work. To close the windows you can use the function destroy all windows. [link to more information](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option to view images is also imshow but on matplotlib. This option allows the image to appear directly on the notebook. To see the different parameters go to the next [link](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html), after imshow to actually see the image use the function show from matplotlib\n",
    "\n",
    "Try to display the color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few useful commands to hide ticks and borders. For this code to work make sure to put your own variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imgcolor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a62dfaa26b7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# this hides the axis ticks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspine\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#hide image border\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mspine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imgcolor' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "for spine in plt.gca().spines.values():  #hide image border\n",
    "    spine.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib also allows the option of zooming the image and a cursor that gives the value of the pixel it's hovering over. When using this option it's important to remember to use plt.figure() with different name between the brackets, when not used it will paint over the last figure.\n",
    "[About matplotlib notebook](https://medium.com/@1522933668924/using-matplotlib-in-jupyter-notebooks-comparing-methods-and-some-tips-python-c38e85b40ba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(1)\n",
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "for spine in plt.gca().spines.values():  #hide image border\n",
    "    spine.set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the color image is not correct, this is because of the color space used on OpenCV. \n",
    "OpenCV reads color images as BGR (Blue Green Red), whereas matplotlib displays RGB (Red Green Blue). To see the image correctly it's necessary to change color spaces.\n",
    "![lena](answerimages/lenabgr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to change color spaces\n",
    "\n",
    "OpenCV has a function that allows you to change the color space of an image, it's [cvtcolor](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_colorspaces/py_colorspaces.html). This function has a lot of possible transformations as you can see when you run the next cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flags = flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the color image we have loaded as an example. We want to change it from BGR to RGB so matplotlib can show the image correcty, use cv2.COLOR_BGR2RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform a grey scale image to binary**\n",
    "\n",
    "To go from a color image to a gray image we can just read de image as a one dimension image with imread, or use cvtcolor with the argument COLOR_RGB2GRAY.\n",
    "\n",
    "To go from gray to binary we will use de function Threshold, the documentation for this function is in the next [link](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#cv2.threshold)\n",
    "\n",
    "When choosing the intensity level for the threshold it's important to know what you are going to use this binary image for. This threshold can be chosen manually, there are also algorithms designed to find the best possible threshold, for example Otsu, these algorithms are possible arguments for the Threshold function.\n",
    "\n",
    "It's important to choose the maxvalue best suited for your image. Normally binary images use the values 0 and 1, so the max value should be 1. To display gray scale images use cmap = 'gray' as the second argument for plt.imshow.\n",
    "\n",
    "[answer cell](#greytobinary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From binary to color image**\n",
    "\n",
    "To go from a binary image to an RGB image first we need to create a color map, this will create a false color image. A color map is a matrix that assigns RGB values to the different intensity leves in our original one dimension image. For example a color map for a binary image is 2X3 matrix, since we have 2 original intensity values, if we had a gray scale 8-bit image we would need a 256X3 color map.\n",
    "\n",
    "To create a color map it's necessary to import the colors from matplotlib, we will be using the function [ListedColorMap](https://matplotlib.org/api/_as_gen/matplotlib.colors.ListedColormap.html#matplotlib.colors.ListedColormap) to create a new color map and apply it to our image.\n",
    "\n",
    "Build manually a color map that makes the white pixels of our binary image red and the black ones yellow.\n",
    "\n",
    "More information about color maps:[1](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap) [2](https://matplotlib.org/tutorials/colors/colormap-manipulation.html)\n",
    "\n",
    "[answer cell](#binarytocolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From RGB to indexed image with 255 levels.**\n",
    "\n",
    "These colormaps allows us to create a new type of image that <font color=green> pesa menos, ocupa menos en memoria</font>, these images are indexed images.\n",
    "\n",
    "An indexed image consist of a matrix with the same rows and columns as the original image and another matrix, that is a colormap. This means that if you have an RGB image with 8-bit pixel depth it will occupy numberofpixelsx3x8 bits but, when that image is an indexed image it will be numberofpixels+(levelsx3x8) bits. The levels indicate the number of colors the indexed image has.\n",
    "\n",
    "Since OpenCv doesn't have a function to go from RGB to index we will be using the matrices already given in map255.mat, these matrices will be saved in a dictionary called maps that contains the following: \n",
    "    - lenaind256\n",
    "    - map256    \n",
    "    - lenaind5    \n",
    "    - map5    \n",
    "    - lenagray5    \n",
    "    - mapgray5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "maps = sio.loadmat('map255.mat')\n",
    "\n",
    "print(maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the matrices map256 and lenaind256 from the dictionary, display lenaind256 as an image in gray scale.\n",
    "Use the function ListedColormap to save map256 as a Colormap and display the indexed image lenaind256 with the new colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From RGB to indexed image with 5 levels.**\n",
    "\n",
    "In this section do the same as in the last, but with the matrices lenaind5 and map5. This was generated as an indexed image with only 5 levels, which means there are only 5 colors in the final image. Can you apreciate the difference in the image?\n",
    "\n",
    "[answer cell](#rgbto5levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From gray scale to indexed image with 5 levels.**\n",
    "\n",
    "Repeat with lenagray5 and mapgray5.\n",
    "\n",
    "[answer cell](#grayto5levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>Las imágenes procesadas con OpenCV se pueden almacenar en disco utilizando el comando\n",
    "imwrite. </font>\n",
    "To save an image to a specified file use the function [imwrite](https://docs.opencv.org/3.0-alpha/modules/imgcodecs/doc/reading_and_writing_images.html#imwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II. Changing the spatial and intensity resolution of an image.**\n",
    "\n",
    "The spatial resolution of an image refers to the number of pixels per row and column. To modify it openCV has the function <a href=\"https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#void%20resize(InputArray%20src,%20OutputArray%20dst,%20Size%20dsize,%20double%20fx,%20double%20fy,%20int%20interpolation)\">resize</a>.\n",
    "Take the gray image of Lena with it's orginal size being 512X512:\n",
    "- Resize it to a 256X256 image\n",
    "- Resize it to a 128X128 image\n",
    "\n",
    "Show the 3 images side by side to apreciate the difference. Using cv2.imshow() it will be easier to see the difference since the windows will be of a different size each. Another way to see the images side by side is with [plt.subplot](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html)\n",
    "\n",
    "[answer cell](#spatialres1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of cv2.imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the smaller image from the last question and resize it to it's original spatial resolution using different interpolations (nearest and bilinear). \n",
    "\n",
    "The interpolation is the method used by the resize function to stimate the values of the new pixels created when enlarging an image.\n",
    "Show the 3 images (original lena, and the 2 new just generated) side by side to apreciate the difference.\n",
    "\n",
    "[answer cell](#spatialres2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For use of cv2.imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensity resolution refers to the number of bits used for each pixel which marks the number of intensity levels in an image. A normal gray scale image has 8 bits per pixel. An RGB image has 8 bits per pixel multiplied by 3 for each color.\n",
    "\n",
    "To change the intensity resolution of our image we will be using basic math applied directly to our image matrix, dividing the maximum level of our image, 255 in this case, by the number given by this formula: X = 256/n (being n the number of levels we want).\n",
    "\n",
    "- Change the intensity resolution in Lena to 16, 4 and 2 and save them in this variables Lena_512_16, Lena_512_4 y Lena_512_2.\n",
    "\n",
    "\n",
    "[answer cell](#intensityres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2 levels we can use threshold\n",
    "Lena_512_2 = imgotsu\n",
    "\n",
    "#4 levels left as example repeat for 16 levels.\n",
    "x = 256 / 4\n",
    "temp = imggray/x\n",
    "temp = np.around(temp)\n",
    "Lena_512_4 = temp*x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III. Histogram and contrast enhacement**\n",
    "\n",
    "A histogram is a way of displaying the pixels of an image that plots the intensity in  the x axis and the number of pixels inthe y axis, this allows you to easily see the tonal distribution of an image.\n",
    "\n",
    "Matplotlib has an specific function for this graphical display: [hist](https://docs.opencv.org/3.1.0/d1/db7/tutorial_py_histogram_begins.html)\n",
    "\n",
    "Display the histograms of the following images: \n",
    "    - Original gray Lena\n",
    "    - Lena_512_16\n",
    "    - Lena_512_4\n",
    "    - Lena_512_2.\n",
    "    \n",
    "[answer cell](#histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tonal distribution of an image is linked to it's contrast, in general we can say that an image has a better contrast when its histogram is wider, or its intensity is not concentrated around one specific value. \n",
    "\n",
    "One way to improve the contrast of an image is through [histogram equalization](https://homepages.inf.ed.ac.uk/rbf/HIPR2/histeq.htm)\n",
    "\n",
    "OpenCV has a function for this: [equalizehist](https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=equalizehist)\n",
    "\n",
    "Read the image lanscape.jpg and equalize its histogram. Display both, the original and new histograms, and both images.\n",
    "\n",
    "[answer cell](#equ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV.Interpretation of colour**\n",
    "\n",
    "Load the image peppers.jpeg, look up the shape of the image and display it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the histogram of each one of the colour components (R, G, B). Remember to change this code to suit your variable names.\n",
    "\n",
    "[answer cell](#peppershist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "plt.figure('hist')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([peppers],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the different channels of the image using the function [split](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html?#split)\n",
    "\n",
    "Display the red channel of the image.\n",
    "\n",
    "[answer cell](#peppersred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the negative of the red channel. To make the negative substract 255 (max value in an image with pixel depth 8) to the image. Keep in mind the order of the operation since an image can´t have negative values. Display this negative.\n",
    "\n",
    "Remerge the image with your new red channel and the original blue and green channels, use the function cv2.merge, an display this new image.\n",
    "\n",
    "[answer cell](#negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two matrices of zeros with the same number of rows and columns as the image peppers and merge them with the original red channel to create a representation of only the red channel of the image.\n",
    "\n",
    "[answer cell](#Onlyred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cells with the answer images</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform a grey scale image to binary\n",
    "<a id='greytobinary'></a>\n",
    "\n",
    "![threshold127](answerimages/threshold127.PNG)\n",
    "![threshold127](answerimages/otsu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From binary to color image\n",
    "<a id='binarytocolor'></a>\n",
    "\n",
    "![lenared](answerimages/lenabincmap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From RGB to indexed image with 5 levels.\n",
    "\n",
    "<a id='rgbto5levels'></a>\n",
    "\n",
    "![5levels](answerimages/5levels.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From gray scale to indexed image with 5 levels.\n",
    "\n",
    "<a id='grayto5levels'></a>\n",
    "\n",
    "![5levels](answerimages/5levelsgray.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial resolution 1\n",
    "\n",
    "<a id='spatialres1'></a>\n",
    "\n",
    "![spatialres1](answerimages/spatialres1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial resolution 2\n",
    "\n",
    "<a id='spatialres2'></a>\n",
    "\n",
    "![spatialres2](answerimages/spatialres2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensity resolution\n",
    "\n",
    "<a id='intensityres'></a>\n",
    "\n",
    "![intensityres](answerimages/intensityres.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram\n",
    "\n",
    "<a id='histogram'></a>\n",
    "\n",
    "![lenahist](answerimages/lenahist.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram equalization\n",
    "\n",
    "<a id='equ'></a>\n",
    "\n",
    "![histequ](answerimages/histequ.PNG)\n",
    "![imgequ](answerimages/imgequ.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peppers histogram\n",
    "\n",
    "<a id='peppershist'></a>\n",
    "\n",
    "![peppershist](answerimages/peppershist.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red channel\n",
    "\n",
    "<a id='peppersred'></a>\n",
    "\n",
    "![peppersred](answerimages/peppersred.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative of red channel\n",
    "\n",
    "<a id='negative'></a>\n",
    "\n",
    "![rednegative](answerimages/rednegative.PNG)  ![peppersneg](answerimages/peppersneg.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only red\n",
    "\n",
    "<a id='Onlyred'></a>\n",
    "\n",
    "![onlyred](answerimages/onlyred.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
